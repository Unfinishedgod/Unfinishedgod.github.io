---
title: "Porto Seguro’s Safe Driver Prediction with Automl.h2o"
author: "최의용"
date: "`r Sys.time()`"
output: 
  html_document:
    highlight: textmate
    theme: simplex
    toc: true
    toc_float: true
    code_folding: show
    df_print: paged
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.align = "center", fig.width = 12, fig.height = 12)
```



<a style="display:scroll;position:fixed;bottom:10px;right:10px;" href="https://unfinishedgod.github.io/" title=”Home"><img
src="https://img.icons8.com/cute-clipart/80/000000/home.png"></a>

<p align="center">
  ![](https://storage.googleapis.com/kaggle-competitions/kaggle/3333/media/driver.png){#id .class width="100%"}<br>
</p>

<br>


# About Automl h2o

Lets Use **AutoML h2o** to analyze the Porto Seguro’s Safe Driver Prediction kaggle. In this time i learned how to use the Automl h2o in R, and it was a topic that i chose while looking for how to use it. There is a lot to be lacking in using the automatic h2o, so I refer to a lot of setes, refer to a kaggle notebook, and write it down.

<br>

# Reference

The following is a reference link in studying h2o automl and the source of the notebook that analyzed Porto Seguro's Safe Driver Prediction using h2o automl in the Kaggle.

- **H2O AutoML**
  - H2O tutorials: [h2o tutorials](http://docs.h2o.ai/h2o-tutorials/latest-stable/index.html)
- **H2O AutoMA & Kaggle**
  - Troy Walters: [h2o AutoML](https://www.kaggle.com/captcalculator/h2o-automl)
  - Bhavesh Ghodasara: [AutoML(h2o) Trial](https://www.kaggle.com/bhavesh09/automl-h2o-trial) 
- **Kaggle**
  - Heads or Tails: [Steering Wheel of Fortune - Porto Seguro EDA](https://www.kaggle.com/headsortails/steering-wheel-of-fortune-porto-seguro-eda)
  - Troy Walters: [A Very Extensive Porto Exploratory Analysis](https://www.kaggle.com/captcalculator/a-very-extensive-porto-exploratory-analysis)

<br>

# Porto Seguro’s Safe Driver Prediction

Now lets get down to Porto Seguro's Safe Driver Prediction. The goal is to predict whether drivers will claim insurance next year through data.

## Avaluation 

The competition will be evaluated as a Normalized Gini Coefficant. First, to understand Gini Coeffient, it its as follows. 

In economics, the Gini coefficient, sometimes called the Gini index or Gini ratio, is a measure of statistical dispersion intended to represent the income or wealth distribution of a nation's residents, and is the most commonly used measurement of inequality. It was developed by the Italian statistician and sociologist Corrado Gini and published in his 1912 paper Variability and Mutability (Italian: Variabilità e mutabilità).

<p align="center">
  ![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Economics_Gini_coefficient.svg/280px-Economics_Gini_coefficient.svg.png
){#id .class width="45%"}<br>
출쳐: [Wikipedia -Gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient)
</p>

## 데이터 파악

- Each column can be classified as follows.
  - ind, reg, car, calc
- The format of the data can be determined by the column name as follows.
  - '_bin': Binary Features
  - '_cat': Categorical Features
  - 그외: Continuous 또는 Ordinal Features
- Values of -1 indicate that the feature was missing from the observation.

<br>

# Preparation

## Packages & Data load

```{r}
library(readr)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(pROC)
library(h2o)
library(caret)
library(corrplot)
library(ggthemes)


train_set <- read_csv("../input/porto-seguro-safe-driver-prediction/train.csv")
test_set <- read_csv("../input/porto-seguro-safe-driver-prediction/test.csv")
```

<br>

## H2O init

First, connect h2o and R through the h2oinit() funcion.

```{r}
h2o.init()
```

<br>

## Data structure {.tabset}

### Data structure

```{r}
str(train_set)
```

### Data summary

```{r}
summary(train_set)
```

<br>

# Data Cleanging

Lets do a data cleanging. As mentioned, the data in "-1" is missing value, so lets change it to NA. And the '_cat' column allows you to change it to a factor format.

```{r}
train_set[train_set == -1] <- NA
test_set[test_set == -1] <- NA

cat_vars <- names(train_set)[grepl('_cat$', names(train_set))]

train_set <- train_set %>%
  mutate_at(.vars = cat_vars, .funs = as.factor)

test_set <- test_set %>%
  mutate_at(.vars = cat_vars, .funs = as.factor)
```

<br>

# Visualization

## Target visualiztion

Lets look at the target variable. 

```{r}
ggplot(data = train_set, aes(x = as.factor(target))) +
    geom_bar(fill = "#D9230F") +
    labs(title = 'Distribution of Target Class',
         x = "Target", 
         y = "Target Count")
```

<br>

## Missing value

### Missing value visualiztion

Lets look at the missing value ratio. Only a few of the 59 columns have significant missing values.

```{r}
data.frame(feature = names(train_set), 
           per_miss = map_dbl(train_set, function(x) { sum(is.na(x)) / length(x) })) %>%
  ggplot(aes(x = reorder(feature, per_miss), y = per_miss)) + 
  geom_bar(stat = 'identity', color = 'white', fill = '#D9230F') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  coord_flip() +
  labs(x = '', y = 'Missing value ratio(%)', title = 'Missing Value by Feature') + 
  scale_y_continuous(labels = scales::percent)
```

### Missing value table

Lets take a closer look at the missing values of each column at the table. If you select only the top 10 and check it, it is as follows.

```{r}
missing_df <- data.frame(feature = names(train_set), 
           per_miss = round(map_dbl(train_set, function(x) { sum(is.na(x)) / length(x) }) * 100,2)) %>% 
  arrange(desc(per_miss)) %>% 
  head(10)

rownames(missing_df) <- NULL

missing_df
```

<br>

## Correlation overview

### Correlation visualization

각 데이터들간의 상관계수 plot을 그려 파악해보도록 하자. 데이터의 갯수가 상당히 많아서 테이블로 표시해도 큰 의미는 없으니 그래프를 통해 간단하게만 보도록 하자.

```{r}
train_set %>%
  select(-starts_with("ps_calc"), -ps_ind_10_bin, -ps_ind_11_bin, -ps_car_10_cat, -id) %>%
  mutate_at(vars(ends_with("cat")), funs(as.integer)) %>%
  mutate_at(vars(ends_with("bin")), funs(as.integer)) %>%
  mutate(target = as.integer(target)) %>%
  cor(use="complete.obs", method = "spearman") %>%
  corrplot(type="lower", tl.col = "black",  diag=FALSE)
```

<br>

# 모델링

## Train / Valid

시각화까지 진행 했으니 이제 모델을 돌려보자. 우선 Training데이터를 Train / valid 데이터로 분류를 해서 테스트를 진행 해보자. 이후에 Test데이터로 평가를 진행 해보려 한다. <br>
 진행 하는데 있어 h2o모델을 돌리기 위해서는 데이터를 `as.h2o()`함수를 통해 형식을 h2o에 맞게 해주어야 하나보다.

```{r}
set.seed(32)
index <- sample(1:nrow(train_set), nrow(train_set) * 0.7)

tiny_train <- train_set[index, ]
train_val <- train_set[-index, ]

tiny_train.hex  <- as.h2o(tiny_train)
train_val.hex  <- as.h2o(train_val)
test.hex <- as.h2o(test_set)


# rm(train, tiny_train, train_val)
# gc()

target <- "target"
predictors <- setdiff(names(tiny_train.hex), target)
```

## 모델 생성

이제 이번 블로그의 핵심인 `h2o.automl()`함수를 사용해서 모델을 돌려보자. h2o.automl에 대해 자세한 사항은 다음을 참고 하자. 
- 참고: [h2o로 모델링 해보기](https://rpubs.com/BBSSDDSD/simple_h2o_intro_usage)

```{r results="hide"}
automl_h2o_models <- h2o.automl(
  x = predictors,
  y = target,
  training_frame    = tiny_train.hex,
  leaderboard_frame = train_val.hex,
  max_runtime_secs = 3000
)

automl_leader <- automl_h2o_models@leader


# Predict on test set
pred_conversion <- h2o.predict(object = automl_leader, newdata = test.hex)

pred_conversion <- as.data.frame(pred_conversion)
Submission <- cbind(test_set$id, pred_conversion)
colnames(Submission) <- c("id", "target")
write.csv(Submission, "Submission_AutoML.csv", row.names = F)
```

# 총평 

h2o.automl을 알게 되어 R에서 적용해볼 기회가 생겼다. <br>
 상당히 많은 난관이 있었는데 첫번째로는 h2o를 R에 재설치 하는것. 패키지가 설치 되어 있어서 정말 놀랐는데 기억을 더듬어 보니, 꽤 오래전에 h2o패키지를 설치 해두었던 적이 있었다. 그래서 오랜만에 실행을 했더니 버전 문제로 warning이 나와서 다시 설치를 하는데 많은 시간을 쏟았다. <br>
 그리고 h2o.automl이 무엇인지 자료 조사 해보는 과정. automl은 어딘가에서 듣기만 했고, h2o는 패키지를 설치 했던 기억만 있지, 이번에 하면서 너무도 생소했었다. r에서 h2o가 어떻게, automl은 또 어떻게 진행되는지 알아보는 시간이 꽤 오래 걸렸다. <br>
 마지막 난관인데, 이 기술들을 가지고 어떻게 써먹을 수 있을까? 하는 문제였다. 어느순간부터 교과서형 공부 하는것을 별로 안좋아하게 되었는데, 100의 공부를 하고 10정도를 실전에 쓰는 느낌? 그래서 이번에도 실전에는 어떻게 활용할 수 있을까 하다가 생각이 났던 것이 캐글. 캐글에서도 많은 자료가 없었고, 적당한 주제와 당장 내가 h2o.automl()로 할 수 있어 보이는 분류 데이터를 찾느라 시간이 많이 걸렸다. <br>
 정말 새로운 '그 무언가'를 해봤다. 어디서 듣기만 했다가 시작한것이 아니라 아예 처음부터 생소한 것들을 공부해가면서 이번 캐글 준비를 해봤는데, 이제 이런것을이 하나둘씩 쌓여가겠지.