---
title: "[R] Porto Seguro’s Safe Driver Prediction"
author: "최의용"
date: "`r Sys.time()`"
output: 
  html_document:
    highlight: textmate
    theme: simplex
    toc: true
    toc_float: true
    code_folding: show
    df_print: paged
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = "center")
```

<head>
<script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-145407326-3', 'auto');
ga('send', 'pageview');

</script>
</head>

<a style="display:scroll;position:fixed;bottom:10px;right:10px;" href="https://unfinishedgod.github.io/" title=”Home"><img
src="https://img.icons8.com/cute-clipart/80/000000/home.png"></a>

<p align="center">
  ![](Porto_Seguro_Safe_Driver_Prediction.PNG){#id .class width="100%"}<br>
    <b>Porto Seguro’s Safe Driver Prediction 링크: [Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/overview)</b><br>
</p>

<br>


# About Automl h2o

**AutoML h2o**를 사용해 캐글의 Porto Seguro’s Safe Driver Prediction를 분석 해보자. 캐글을 병행하면서 R에서 Automl h2o를 사용할 수 있는 방법을 알게 되었고, 이를 어떻게 사용할 수 있을까 찾다가 선정한 주제였다. 당장은 Automl h2o사용에 있어서 부족한게 많아 상당히 많은 사이트를 참고 하고, 캐글 노트북을 참고하고 필사하게 되었다. 높은 난이도로 R with Automl h2o라는 주제의 블로그는 다음에 시간이 남을때 써보기로 하고 이번에는 Reference를 먼저 소개 하도록 하겠다.

<br>

# Reference

다음은 H2o automl을 공부하는데 있어서 참고 할만한 링크와 Kaggle에서 Porto Seguro's Safe Driver Prediction를 h2o automl을 사용해서 분석한 노트북의 출처이다.

- **H2O AutoML**
  - xwMOOC님 블로그: [순수 H2O AutoML](https://statkclee.github.io/model/model-h2o-automl.html)
  - BBSSDDSD Rpubs: [H2O 소개 및 간단한 사용법](https://rpubs.com/BBSSDDSD/simple_h2o_intro_usage)
  - H2O 튜토리얼: [h2o tutorials](http://docs.h2o.ai/h2o-tutorials/latest-stable/index.html)
- **H2O AutoMA & Kaggle**
  - Troy Walters: [h2o AutoML](https://www.kaggle.com/captcalculator/h2o-automl)
  - Bhavesh Ghodasara: [AutoML(h2o) Trial](https://www.kaggle.com/bhavesh09/automl-h2o-trial) 
- **Kaggle**
  - Heads or Tails: [Steering Wheel of Fortune - Porto Seguro EDA](https://www.kaggle.com/headsortails/steering-wheel-of-fortune-porto-seguro-eda)
  - Troy Walters: [A Very Extensive Porto Exploratory Analysis](https://www.kaggle.com/captcalculator/a-very-extensive-porto-exploratory-analysis)
  - 사자처럼 우아하게님 블로그: [Porto Seguro's Safe Driver Prediction 대회 소개 / 지니계수 란?](https://yseon99.tistory.com/55)

<br>

# Porto Seguro’s Safe Driver Prediction

이제 본격적으로 Porto Seguro’s Safe Driver Prediction에 대해 알아보도록 하자. 데이터를 통해 운전자가 내년에 보험청구를 하는지 여부를 예측하는것이 목표다. 

## 평가 

이번 대회는 Normalized Gini Coefficient로 평가를 하게 된다. 먼저 Gini Coefficient를 이해 해보자면 다음과 같다.

지니 계수( - 係數, 영어: Gini coefficient, 이탈리아어: coefficiente di Gini)는 경제적 불평등(소득 불균형)을 계수화 한 것이다. 오늘날 가장 널리 사용되는, 불평등의 정도를 나타내는 통계학적 지수로, 이탈리아의 통계학자인 코라도 지니(Corrado Gini)가 1912년 발표한 논문 "Variabilità e mutabilità"에 처음 소개되었다. 서로 다른 로렌츠 곡선들이 교차하는 경우 비교하기가 곤란하다는 로렌츠 곡선의 단점을 보완할 수 있다. 지니 계수는 소득 분배의 불평등함 외에도, 부의 편중이나 에너지 소비에 있어서의 불평등함에도 응용된다.

<p align="center">
  ![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Economics_Gini_coefficient.svg/280px-Economics_Gini_coefficient.svg.png
){#id .class width="45%"}<br>
출쳐: [위키백과 지니계수](https://ko.wikipedia.org/wiki/%EC%A7%80%EB%8B%88_%EA%B3%84%EC%88%98)
</p>


# 사전 준비

```{r}
# library(readr)
# library(tidyverse)
# library(ggplot2)
# library(dplyr)
# library(pROC)
# library(h2o)
# library(caret)
# library(aws.s3)
```


```{r}
# h2o.init()
# 
# train_set <- read_csv("/home/owen/file/train.csv")
# test_set <- read_csv("/home/owen/file/test.csv")
# 
# 
# 
# #Setting Missing values to NA. Converting _cat variables to categorical and creating dummy variable for those.
# # Set missing values to NA
# train_set[train_set == -1] <- NA
# test_set[test_set == -1] <- NA
# # collect the categorical variable names
# cat_vars <- names(train_set)[grepl('_cat$', names(train_set))]
# 
# # convert categorical features to factors
# train_set <- train_set %>%
#   mutate_at(.vars = cat_vars, .funs = as.factor)
# 
# test_set <- test_set %>%
#   mutate_at(.vars = cat_vars, .funs = as.factor)
# 
# #One hot encode the factor variables
# #train_set <- model.matrix(~ . - 1, data = train_set)
```

# 시각화 

## Target Feature Analysis

```{r}
# ggplot(data = train_set, aes(x = as.factor(target))) + 
#     geom_bar(fill = '#84a5a3') + 
#     labs(title = 'Distribution of Target Class (1 = claim filed)')
```

## 결측치 파악

```{r}
data.frame(feature = names(dtrain), 
           per_miss = map_dbl(dtrain, function(x) { sum(x == - 1) / length(x) })) %>%
    ggplot(aes(x = reorder(feature, -per_miss), y = per_miss)) + 
    geom_bar(stat = 'identity', color = 'white', fill = '#5a64cd') +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
    labs(x = '', y = '% missing', title = 'Missing Values by Feature') + 
    scale_y_continuous(labels = scales::percent)
```

## 상관 계수 파악 

```{r}
# Get features names that are not binary or categorical
cont_vars <- names(dtrain)[!grepl("_cat|_bin", names(dtrain))]

corrplot(cor(dtrain[, cont_vars][3:length(cont_vars)]), 
         type = 'lower', 
         col = colorRampPalette(c('#feeb8c', '#5a64cd'))(50),
         tl.col = 'grey40',
         mar = c(0,0,1,0),
         title = 'Correlation Matrix of Continuous Features')
```


# 모델링

```{r}
# #Splitting Datasets into train and validation. I am taking 75% data. 
# #I will use cross validation in next version.
# set.seed(32)
# 
# # index <- createDataPartition(train_set[,"target"], p = 0.75, list = FALSE)
# 
# index <- sample(1:nrow(train_set), nrow(train_set) * 0.7)
# 
# tiny_train <- train_set[index, ]
# train_val <- train_set[-index, ]
# 
# tiny_train.hex  <- as.h2o(tiny_train)
# train_val.hex  <- as.h2o(train_val)
# test.hex <- as.h2o(test_set)
# 
# 
# # rm(train, tiny_train, train_val)
# # gc()
# 
# # Preparing Target and predictors.
# target <- "target"
# predictors <- setdiff(names(tiny_train.hex), target)
```


```{r results="hide"}
# # Let's run automl now.
# automl_h2o_models <- h2o.automl(
#   x = predictors, 
#   y = target,
#   training_frame    = tiny_train.hex,
#   leaderboard_frame = train_val.hex,
#   max_runtime_secs = 3000
# )
# 
# automl_leader <- automl_h2o_models@leader
# 
# 
# automl_h2o_models@leaderboard %>% 
#     as.data.frame()
```


```{r}
# # Predict on test set
# pred_conversion <- h2o.predict(object = automl_leader, newdata = test.hex)
# 
# pred_conversion <- as.data.frame(pred_conversion)
# Submission <- cbind(test_set$id, pred_conversion)
# colnames(Submission) <- c("id", "target")
# write.csv(Submission, "Submission_AutoML.csv", row.names = F)
# 
# # Any results you write to the current directory are saved as output.
```

# Score
